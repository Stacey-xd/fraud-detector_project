{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the Classes\n",
    "- SMOTE was applied **only to the training data**, creating synthetic fraud examples to even out the rare class.\n",
    "\n",
    "### Main XGBoost Settings\n",
    "- **100 trees** (`n_estimators=100`): Chosen to capture complex patterns without excessive training time.  \n",
    "- **Max depth 4** (`max_depth=4`): Limits tree size to prevent overfitting on noise.  \n",
    "- **Learning rate 0.1** (`learning_rate=0.1`): Ensures gradual updates for stable convergence.  \n",
    "- **subsample=0.8**: Each tree was trained on 80% of rows to improve generalization.  \n",
    "- **colsample_bytree=0.8**: Each tree used 80% of features to increase model diversity.  \n",
    "- **eval_metric='logloss'**: Optimizes the probability estimates, which is critical in fraud detection.  \n",
    "- **random_state=42**: Fixed seed for reproducible results.  \n",
    "- **scale_pos_weight=1**: No additional class weighting was needed since SMOTE had already balanced the classes.\n",
    "\n",
    "### Prediction with a 0.7 Threshold\n",
    "- The model outputs a probability for each transaction being fraudulent.  \n",
    "- A threshold of **0.7** was chosen (instead of the default 0.5) to reduce false positives by only flagging transactions when the model is highly confident.\n",
    "\n",
    "### Evaluation\n",
    "- A **confusion matrix** and **classification report** (precision, recall, F1-score) were generated on the held-out test set.  \n",
    "- Class labels are stated as **“Legit”** (normal) and **“Fraud”**.\n",
    "\n",
    "### Model Saving\n",
    "- The trained model was saved as `models/xgboost_smote_eval_[XX].pkl`, where `[XX]` increments automatically to preserve previous versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:01:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[56485   166]\n",
      " [ 2317 54334]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Legit     0.9606    0.9971    0.9785     56651\n",
      "       Fraud     0.9970    0.9591    0.9777     56651\n",
      "\n",
      "    accuracy                         0.9781    113302\n",
      "   macro avg     0.9788    0.9781    0.9781    113302\n",
      "weighted avg     0.9788    0.9781    0.9781    113302\n",
      "\n",
      "Model saved to models/xgboost_smote_eval_01.pkl\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Apply SMOTE to training set only\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train XGBoost\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    scale_pos_weight=1  # ми вже застосували SMOTE, тому балансування не потрібне\n",
    ")\n",
    "model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Predict with custom threshold\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.7\n",
    "y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4, target_names=[\"Legit\", \"Fraud\"]))\n",
    "\n",
    "# Save model with auto-incrementing name\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "base_filename = \"xgboost_smote_eval\"\n",
    "ext = \".pkl\"\n",
    "i = 0\n",
    "while True:\n",
    "    filename = f\"{base_filename}{'' if i == 0 else f'_{i:02d}'}{ext}\"\n",
    "    filepath = os.path.join(model_dir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "joblib.dump(model, filepath)\n",
    "print(f\"Model saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What Changed in This XGBoost Run\n",
    "\n",
    "**No SMOTE this time**\n",
    "   - Training is performed directly on the original, cleaned dataset (`creditcard_isoforest_cleaned_001.csv`).  \n",
    "   - Class imbalance is handled via `scale_pos_weight` instead of synthetic oversampling.\n",
    "\n",
    "**Tuned Hyperparameters**  \n",
    "   - **`n_estimators=500`**: Increased number of trees to capture more complex patterns.  \n",
    "   - **`max_depth=8`**: Deeper trees to allow the model to learn higher-order interactions.  \n",
    "   - **`learning_rate=0.2`**: Faster convergence, since fewer boosting rounds are needed.  \n",
    "   - **`subsample=1.0`**: Uses 100% of data for each tree (no row sampling).  \n",
    "   - **`colsample_bytree=0.6`**: Each tree considers 60% of features, adding randomness to reduce overfitting.  \n",
    "   - **`gamma=0`**: No minimum loss reduction required to make a further split, allowing more splits.  \n",
    "   - **`scale_pos_weight=(neg/pos)`**: Automatically balances the rare fraud class by weighting positive examples according to the train split’s class ratio.  \n",
    "\n",
    "**Same Custom Threshold**  \n",
    "   - Predictions are binarized at **0.7** to remain conservative and minimize false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[56600     4]\n",
      " [   15    70]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Legit     0.9997    0.9999    0.9998     56604\n",
      "       Fraud     0.9459    0.8235    0.8805        85\n",
      "\n",
      "    accuracy                         0.9997     56689\n",
      "   macro avg     0.9728    0.9117    0.9402     56689\n",
      "weighted avg     0.9997    0.9997    0.9997     56689\n",
      "\n",
      "Model saved to models/xgboost_tuned_eval.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset (without SMOTE)\n",
    "df = pd.read_csv(\"data/creditcard_isoforest_cleaned_001.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# 3. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Train XGBoost with best hyperparameters\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.2,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=0.6,\n",
    "    gamma=0,\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict with threshold\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.7\n",
    "y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4, target_names=[\"Legit\", \"Fraud\"]))\n",
    "\n",
    "# Save model with auto-incrementing name\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "base_filename = \"xgboost_tuned_eval\"\n",
    "ext = \".pkl\"\n",
    "i = 0\n",
    "while True:\n",
    "    filename = f\"{base_filename}{'' if i == 0 else f'_{i:02d}'}{ext}\"\n",
    "    filepath = os.path.join(model_dir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "joblib.dump(model, filepath)\n",
    "print(f\"Model saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Model Update**  \n",
    "   - A **deeper Autoencoder** was implemented to better capture complex patterns in legitimate transaction data.  \n",
    "   - Architecture includes:\n",
    "     - Encoder: `input → 128 → 64 → 32 → 16`\n",
    "     - Decoder: `16 → 32 → 64 → 128 → input`\n",
    "\n",
    "2. **Training Configuration**  \n",
    "   - Trained on only legitimate transactions (`Class == 0`) using MSE loss.  \n",
    "   - Optimizer: Adam with a reduced learning rate (`1e-4`) for more stable convergence.  \n",
    "   - Epochs: 50\n",
    "\n",
    "3. **Reconstruction Threshold**  \n",
    "   - A new threshold was calculated using the **mean + 3×std** of reconstruction error on legit data (based on the deeper model’s output).  \n",
    "   - Used to classify anomalies on the full test set.\n",
    "\n",
    "4. **Model Saving**  \n",
    "   - The model was saved under an incremented name format to avoid overwriting earlier versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Hyperparameter Tuning\n",
    "\n",
    "1. **Custom Scoring Metric**  \n",
    "   - Optimization was based on the **F1-score of the fraud class** (`pos_label=1`) to emphasize the model’s ability to detect rare fraudulent transactions.\n",
    "\n",
    "2. **Parameter Grid**  \n",
    "   A wide search space was explored to capture both complexity and regularization:\n",
    "   - `n_estimators`: [100, 200, 300, 500] – number of boosting rounds.\n",
    "   - `max_depth`: [3, 4, 5, 6, 7, 8] – controls model complexity.\n",
    "   - `learning_rate`: [0.01, 0.05, 0.1, 0.2] – smaller values allow better convergence.\n",
    "   - `subsample`: [0.6, 0.8, 1.0] – random sampling of training instances per tree.\n",
    "   - `colsample_bytree`: [0.6, 0.8, 1.0] – fraction of features per tree.\n",
    "   - `gamma`: [0, 0.1, 0.3, 0.5] – minimum loss reduction to make a split.\n",
    "   - `scale_pos_weight`: [scale, scale × 0.5, scale × 2] – compensates for class imbalance.\n",
    "\n",
    "3. **Search Strategy**  \n",
    "   - Used `RandomizedSearchCV` with **30 combinations** and **3-fold cross-validation**.  \n",
    "   - Parallelized over all cores (`n_jobs=-1`) for faster exploration.  \n",
    "   - Best parameters and scores were printed for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=8, n_estimators=500, scale_pos_weight=331.9824046920821, subsample=1.0; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=8, n_estimators=500, scale_pos_weight=331.9824046920821, subsample=1.0; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=8, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=1.0; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=8, n_estimators=500, scale_pos_weight=331.9824046920821, subsample=1.0; total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=8, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=1.0; total time=   9.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=6, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=  13.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=6, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=  13.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=6, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=  13.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=8, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=1.0; total time=   9.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=1327.9296187683285, subsample=0.6; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=  11.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=1327.9296187683285, subsample=0.6; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=  12.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=  11.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, scale_pos_weight=1327.9296187683285, subsample=0.6; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=  13.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, scale_pos_weight=331.9824046920821, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.2, max_depth=7, n_estimators=500, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.2, max_depth=7, n_estimators=500, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.2, max_depth=7, n_estimators=500, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=500, scale_pos_weight=1327.9296187683285, subsample=0.8; total time=  13.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, scale_pos_weight=331.9824046920821, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, scale_pos_weight=331.9824046920821, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=300, scale_pos_weight=331.9824046920821, subsample=0.6; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=300, scale_pos_weight=331.9824046920821, subsample=0.6; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=300, scale_pos_weight=331.9824046920821, subsample=0.6; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=200, scale_pos_weight=331.9824046920821, subsample=0.6; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=200, scale_pos_weight=331.9824046920821, subsample=0.6; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=200, scale_pos_weight=331.9824046920821, subsample=0.6; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:12:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=300, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=300, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=500, scale_pos_weight=331.9824046920821, subsample=1.0; total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=300, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=500, scale_pos_weight=331.9824046920821, subsample=1.0; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=500, scale_pos_weight=331.9824046920821, subsample=1.0; total time=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=1.0; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=1.0; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=0.6; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=0.6; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=0.6; total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=8, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=300, scale_pos_weight=331.9824046920821, subsample=0.8; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=8, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=300, scale_pos_weight=331.9824046920821, subsample=0.8; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=8, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, scale_pos_weight=663.9648093841643, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=300, scale_pos_weight=331.9824046920821, subsample=0.8; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=1.0; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, scale_pos_weight=331.9824046920821, subsample=1.0; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, scale_pos_weight=331.9824046920821, subsample=1.0; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, scale_pos_weight=331.9824046920821, subsample=0.8; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, scale_pos_weight=331.9824046920821, subsample=0.8; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, scale_pos_weight=331.9824046920821, subsample=0.8; total time=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, scale_pos_weight=331.9824046920821, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=4, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=4, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=4, n_estimators=300, scale_pos_weight=1327.9296187683285, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=8, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=0.6; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=8, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=0.6; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=8, n_estimators=200, scale_pos_weight=663.9648093841643, subsample=0.6; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:13:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'subsample': 1.0, 'scale_pos_weight': 331.9824046920821, 'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.2, 'gamma': 0, 'colsample_bytree': 0.6}\n",
      "Best score: 0.842701306178682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5],\n",
    "    'scale_pos_weight': [scale, scale * 0.5, scale * 2],\n",
    "}\n",
    "\n",
    "# Create model\n",
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define custom scorer for fraud class only\n",
    "scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "# Randomized search\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_grid,\n",
    "    scoring=scorer,\n",
    "    n_iter=30,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(\"Best score:\", search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Model Improvements**\n",
    "   - Added two `Dropout(0.5)` layers (instead of 0.3) to reduce overfitting.\n",
    "   - Used `BCEWithLogitsLoss` instead of `BCELoss`, which is numerically more stable and avoids applying `Sigmoid` inside the model.\n",
    "\n",
    "2. **Class Imbalance Handling**\n",
    "   - Passed `pos_weight` directly to `BCEWithLogitsLoss` based on the ratio of legit to fraud cases in the training set.\n",
    "\n",
    "3. **Optimization**\n",
    "   - Replaced the standard `Adam` optimizer with `AdamW`, which adds better weight decay regularization (`weight_decay=1e-5`).\n",
    "\n",
    "4. **Batch Size**\n",
    "   - Increased the batch size to **2048** for more stable gradient estimates.\n",
    "\n",
    "5. **Early Stopping**\n",
    "   - Implemented early stopping with a **patience of 10 epochs**, saving the best model based on training loss.\n",
    "\n",
    "6. **Evaluation**\n",
    "   - Applied `sigmoid` manually during evaluation.\n",
    "   - Used a **custom threshold of 0.7** to reduce false positives.\n",
    "\n",
    "7. **Model Saving**\n",
    "   - Saved the final model weights as `fraud_nn_tuned.pt` in the `models/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions XGBoost\n",
    "\n",
    "XGBoost proved to be one of the most powerful classifiers in this fraud detection task. Here's a breakdown of the results:\n",
    "\n",
    "- **XGBoost with tuned hyperparameters (no SMOTE):**\n",
    "  - Achieved **high precision and recall**, especially for the minority fraud class.\n",
    "  - Using `scale_pos_weight` instead of oversampling allowed the model to stay robust without overfitting.\n",
    "  - Best generalization and production-readiness among all tree-based models tested.\n",
    "\n",
    "- **XGBoost with SMOTE:**\n",
    "  - Performance appeared good at first (high recall), but closer inspection revealed **overfitting**.\n",
    "  - Model tended to classify too many transactions as fraud, causing a drop in precision.\n",
    "  - Less reliable on unseen data compared to the tuned version without SMOTE.\n",
    "\n",
    "The best-performing XGBoost model was the one trained on the cleaned dataset **without SMOTE**, but with proper **class weight scaling** and tuned hyperparameters. It balanced performance and generalization very well, making it a strong candidate for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
