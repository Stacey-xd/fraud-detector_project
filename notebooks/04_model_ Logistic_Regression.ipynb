{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with SMOTE for Credit Card Fraud Detection\n",
    "\n",
    "### Data Loading\n",
    "- Loads a pre-processed dataset from emissions: `creditcard_isoforest_cleaned_001.csv`.\n",
    "- Splits the data into:\n",
    "  - `X`: Features\n",
    "  - `y`: Target variable (`Class`: 0 = Legit, 1 = Fraud)\n",
    "\n",
    "### Train-Test Split\n",
    "- Uses `train_test_split` with stratification to preserve class distribution.\n",
    "- Test set size: **20%**\n",
    "\n",
    "### Class Balancing with SMOTE\n",
    "- Uses **SMOTE** only on the training data.\n",
    "- SMOTE creates new fake fraud cases to balance the number of fraud and normal transactions.\n",
    "\n",
    "### Model Training\n",
    "- Trains a `LogisticRegression` model with the following settings:\n",
    "\t- penalty=\"l1\": Uses L1 regularization, which helps the model automatically ignore less important features by shrinking their coefficients to zero.\n",
    "This is especially useful for this dataset, which contains 30 numerical features (mostly PCA components). L1 helps to reduce noise and makes the model more interpretable.\n",
    "\t- solver=\"liblinear\": This solver is specifically designed for L1 regularization and works well on small to medium-sized datasets like this one (≈285K rows, 30 features).\n",
    "It ensures stability and good convergence when working with binary classification.\n",
    "\t- class_weight=\"balanced\": Since fraud cases make up less than 0.2% of the dataset, this option automatically balances the class weights, forcing the model to pay more attention to rare fraud cases during training.\n",
    "\t- max_iter=1000: Increases the number of training iterations to ensure convergence, which is especially important when using regularization and class reweighting.\n",
    "\n",
    "### Prediction with a custom threshold\n",
    "\n",
    "Instead of using the default threshold of **0.5**, a **customized threshold of 0.7** was applied when converting the predicted probabilities into binary class labels:\n",
    "\n",
    "- The model outputs the probability that the transaction is fraudulent.\n",
    "- By default, if this probability is ≥ 0.5, the transaction is classified as fraudulent.\n",
    "- However, in very **unbalanced datasets** such as this one, where **fraud events are extremely rare**, a threshold of 0.5 can result in **a high number of false positives**.\n",
    "\n",
    "Benefits of using 0.7\n",
    "\n",
    "- Reduces the number of false positives: Flagging too many legitimate transactions as fraudulent can lead to user dissatisfaction and unnecessary manual checks.\n",
    "- Improves accuracy: A higher threshold makes the model more conservative, flagging a transaction as fraudulent only when there is a high degree of certainty that it is fraudulent.\n",
    "- Better for business**: This solution balances **model efficiency** with **practical impact** by minimizing disruption to honest users.\n",
    "\n",
    "### Evaluation\n",
    "- Displays:\n",
    "  - Confusion matrix\n",
    "  - Classification report with precision, recall, and F1-score\n",
    "- Labels: `\"Legit\"` and `\"Fraud\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[55842   762]\n",
      " [    9    76]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Legit     0.9998    0.9865    0.9931     56604\n",
      "       Fraud     0.0907    0.8941    0.1647        85\n",
      "\n",
      "    accuracy                         0.9864     56689\n",
      "   macro avg     0.5453    0.9403    0.5789     56689\n",
      "weighted avg     0.9985    0.9864    0.9919     56689\n",
      "\n",
      "Model saved to models/logistic_regression_clean_eval_08.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the cleaned and scaled dataset\n",
    "df = pd.read_csv(\"data/creditcard_isoforest_cleaned_001.csv\")\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Apply SMOTE to training set only\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train Logistic Regression with L1 regularization\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    penalty=\"l1\",\n",
    "    solver=\"liblinear\"\n",
    ")\n",
    "model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Predict with lowered threshold\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.7\n",
    "y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4, target_names=[\"Legit\", \"Fraud\"]))\n",
    "\n",
    "# Save model with auto-incrementing name\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "base_filename = \"logistic_regression_clean_eval\"\n",
    "ext = \".pkl\"\n",
    "i = 0\n",
    "while True:\n",
    "    filename = f\"{base_filename}{'' if i == 0 else f'_{i:02d}'}{ext}\"\n",
    "    filepath = os.path.join(model_dir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "joblib.dump(model, filepath)\n",
    "print(f\"Model saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Model Selection\n",
    "\n",
    "After experimenting with several parameter configurations for Logistic Regression, I retained only the **best-performing runs** to ensure meaningful comparison.\n",
    "\n",
    "\n",
    "**Classification Report**\n",
    "\n",
    "| Class           | Precision | Recall | F1-score | Support |\n",
    "|------------------|-----------|--------|----------|---------|\n",
    "| Legit            | 0.9998    | 0.9868 | 0.9932   | 56,651  |\n",
    "| Fraud            | 0.0988    | 0.8632 | 0.1773   | 95      |\n",
    "| **Accuracy**     |           |        | **0.9866** | 56,746  |\n",
    "| **Macro avg**    | 0.5493    | 0.9250 | **0.5853** | 56,746  |\n",
    "| **Weighted avg** | 0.9983    | 0.9866 | **0.9919** | 56,746  |\n",
    "\n",
    "> **Model saved to:** `models/logistic_regression_clean_eval_06.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[56122   482]\n",
      " [    9    76]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Legit     0.9998    0.9915    0.9956     56604\n",
      "       Fraud     0.1362    0.8941    0.2364        85\n",
      "\n",
      "    accuracy                         0.9913     56689\n",
      "   macro avg     0.5680    0.9428    0.6160     56689\n",
      "weighted avg     0.9985    0.9913    0.9945     56689\n",
      "\n",
      "Model saved to models/logistic_regression_bsmote_eval_02.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Load the cleaned and scaled dataset\n",
    "df = pd.read_csv(\"data/creditcard_isoforest_cleaned_001.csv\")\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Apply BorderlineSMOTE to training set only\n",
    "bsmote = BorderlineSMOTE(random_state=42, kind='borderline-1')\n",
    "X_train_bsm, y_train_bsm = bsmote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train Logistic Regression with L1 regularization\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    penalty=\"l1\",\n",
    "    solver=\"liblinear\"\n",
    ")\n",
    "model.fit(X_train_bsm, y_train_bsm)\n",
    "\n",
    "# Predict with lowered threshold\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.7\n",
    "y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4, target_names=[\"Legit\", \"Fraud\"]))\n",
    "\n",
    "# Save model with auto-incrementing name\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "base_filename = \"logistic_regression_bsmote_eval\"\n",
    "ext = \".pkl\"\n",
    "i = 0\n",
    "while True:\n",
    "    filename = f\"{base_filename}{'' if i == 0 else f'_{i:02d}'}{ext}\"\n",
    "    filepath = os.path.join(model_dir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "joblib.dump(model, filepath)\n",
    "print(f\"Model saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balancing with BorderlineSMOTE\n",
    "\n",
    "- Standard SMOTE was replaced by **BorderlineSMOTE (kind='borderline-1')**, applied only to the training set.  \n",
    "- **Reason**: BorderlineSMOTE synthesizes examples near the class boundary, which helps the classifier learn the subtle patterns of fraud cases that lie close to legitimate transactions.\n",
    "\n",
    "### Model Training\n",
    "\n",
    "A `LogisticRegression` model was trained on the BorderlineSMOTE-resampled data with the following settings:\n",
    "\n",
    "- `penalty=\"l1\"`  \n",
    "  **L1 regularization** was used to drive many feature coefficients to zero, effectively selecting only the most informative variables out of the 30 PCA-derived features.\n",
    "\n",
    "- `solver=\"liblinear\"`  \n",
    "  The **liblinear** solver was chosen because it reliably supports L1 penalties and performs efficiently on small-to-medium datasets (≈230 K training samples, 30 features).\n",
    "\n",
    "- `class_weight=\"balanced\"`  \n",
    "  Class weights were automatically scaled inversely to class frequencies. Since fraud cases represent less than 0.2 % of the data, this forces the model to assign higher importance to minority (fraud) examples.\n",
    "\n",
    "- `max_iter=1000`  \n",
    "  The maximum number of optimization iterations was increased to **ensure full convergence**, especially important when using both regularization and imbalanced class weights.\n",
    "\n",
    "### Prediction with Custom Threshold\n",
    "\n",
    "Predicted fraud probabilities were converted into binary labels using **threshold = 0.7** instead of the default 0.5.  \n",
    "- **Justification**:  \n",
    "  - A **higher threshold** reduces false positives, minimizing the number of legitimate transactions flagged as fraud and improving user experience.  \n",
    "  - This conservative approach ensures that only highly confident predictions are labeled as fraudulent.\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "- A **confusion matrix** and **classification report** (precision, recall, F1-score) were generated, using class labels `Legit` and `Fraud`.  \n",
    "- The final model was saved with an auto-incremented filename in the `models/` directory, ready for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions Logistic Regression\n",
    "\n",
    "1. **General Performance**\n",
    "   - All logistic regression models achieved **very high accuracy (>97%)**, but this metric is misleading due to class imbalance.\n",
    "   - The key focus was on detecting **fraud cases** (minority class), which had only 95 instances in the test set.\n",
    "\n",
    "2. **Recall on Fraud Class**\n",
    "   - All models achieved **high recall** (≈0.87) for fraud, meaning they correctly identified most frauds.\n",
    "   - This came at the cost of **very low precision** (≈0.05–0.11), indicating many false positives.\n",
    "\n",
    "3. **Balanced SMOTE Models**\n",
    "   - Models like `logistic_regression_bsmote_eval.pkl` and its variations:\n",
    "     - Achieved **slightly higher precision** (up to 0.11) on the fraud class.\n",
    "     - F1-score was still low (max ≈0.20).\n",
    "     - ROC AUC varied between **0.927–0.944**, showing decent separation ability.\n",
    "\n",
    "4. **Cleaned-Only Models**\n",
    "   - Models without SMOTE (e.g. `logistic_regression_clean_eval_*.pkl`):\n",
    "     - Had **extremely consistent recall ≈0.8737** across all variants.\n",
    "     - Precision remained very low (~0.0529), suggesting limited improvement.\n",
    "     - Slight increase in ROC AUC (**up to 0.9690** in the best case).\n",
    "     - Many of these models were effectively **identical**, suggesting the optimization had converged.\n",
    "\n",
    "5. **Conclusion**\n",
    "   - Logistic regression is not suitable for fraud detection in this case.\n",
    "   - Despite its good recall, the **model is too often wrong**, labeling legitimate transactions as fraudulent.\n",
    "   - A F1-score of < 0.20** indicates low overall quality.\n",
    "   - The models are not ready for actual use in the banking environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
